# Conditional Poisson Process {#conditional-compound-process}

A counting process $\{N(t)\}$ is a *conditional Poisson process* if $N(t)$ has a Poisson distribution with rate $\Lambda$, where $\Lambda$ is a **random variable**. We refer to the rate $\Lambda$ as a *random intensity rate*. 

The *conditional* distribution of number of arrivals in the time interval between $s$ and $t + s$ is given by
$$
P\left(N(t + s) - N(s) = m\right|\Lambda = \lambda) = \mathrm{dpois}(m, \lambda t)
$$
In other words, the conditional distribution of $N(t + s) - N(s)$ given $\Lambda = \lambda$ is Poisson with rate $\lambda t$.

Usually, we don't know $\Lambda = \lambda$. The *marginal* (unconditional) distribution of $N(T + s) - N(s)$ is given by
$$
P\left(N(t + s) - N(s) = m\right) = \int_0^\infty  \mathrm{dpois}(m, \lambda t) \, f_\Lambda(\lambda) \, d\lambda = \int_0^\infty \frac{(\lambda t)^m}{m!} e^{-\lambda t} f_\Lambda(\lambda)\, d\lambda
$$
where $f|_\Lambda$ is the density function associated with the random intensity $\Lambda$. 

### Example 

Suppose $\Lambda$ is uniform on the interval $[0, 2]$. **Find the mistake in the following argument**

\begin{align*}
P(N(t) = 1) &= \int_0^2 \frac{(\lambda t)^1}{1!} \frac 12 \, d\lambda \\
&=\frac t2 \int_0^2 \lambda \, d\lambda\\
&= \frac t2 \times 2 = t
\end{align*}


Note that this cannot be correct! When $t = 2$, this tells us $P(N(2) = 1) = 2$, which makes no sense. Where is the mistake?

::: callout-tryit
Show that the correct answer is $P(N(t) = 1) = \frac{1 - e^{-2t}(2t + 1)}{2t}$
:::

We plot this from $t = 0$ to $t = 10$ to see that the probability is increasing, starts at 0, peaks at some value of time for which exactly one arrival is most likely, and then goes back to zero (because as $t$ gets big, we expect to have more than 1 arrival in the time interval $[0, t]$.)

```{r}
curve( (1 - exp(-2*x)* (2*x + 1))/(2*x), from = 0.0001, to = 10)
```

### Example

In this example, I show you how to compute two integrals using a **very** common trick in probability. The trick to doing **many** integrals of this type that come up in probability is to recognize them as *almost* the integral of a probability density function. More precisely, they are integrals of a probability density function times some constant. (Sometimes, they are integrals that represent the *mean* or *second moment*, but not today.) If we can figure out what the constant is, then we are good! Let's see how it works in practice.

The first is $\int_0^\infty 7 e^{-2x}\, dx$. You have to find that the pdf of an exponential random variable is $\lambda e^{-\lambda x}$. We know that pdfs always integrate out to 1, so we do the following:

\begin{align*}
\int_0^\infty 7 e^{-2x}\, dx &= \frac 72 \int_0^\infty 2 e^{-2x}\, dx\\
&= \frac 72
\end{align*}


The second is $\int_0^\infty x^n e^{-sx}\, dx$. You could think that this is related to $E[X^n]$ for an exponential random variable, and you would be right. But, that is not the easy way to do it. You have to know the pdf of a gamma random variable: $\frac {1}{\Gamma(r)} \beta^r {x^{r - 1}} {e^{-\beta x}}$, where $\Gamma$ is the gamma function, given in R via $\texttt{gamma}$. We have:


\begin{align*}
\int_0^\infty  x^n e^{-sx}\, dx &= \frac{\Gamma(n + 1)}{s^{n + 1}} \int_0^\infty \frac{1}{\Gamma(n + 1)} s^{n + 1} x^{(n + 1) - 1} e^{-sx}\, dx   \\
&= \frac{\Gamma(n + 1)}{s^{n + 1}}
\end{align*}

If $n$ is an integer, $\Gamma(n + 1) = n!$.

::: callout-tryit
Use the above trick to compute $\int_0^1 x^3(1 - x)^4\, dx$. Hint: look at the pdf of a beta distribution. Compare your answer (it should be a number) to what Wolfram alpha gives.
:::


### Example {#sec-poissongeometric}

We show that if $\Lambda$ has an exponential distribution with mean $1/r$ (rate = $r$), then the marginal distribution of $N(t)$ is **geometric**.


\begin{align*}
P(N(t) = n) &= \int_0^\infty \frac{(\lambda t)^n}{n!} e^{-\lambda t} r e^{-\lambda r} \, d\lambda \\
&= \frac {t^n}{n!} \int_0^\infty \lambda^n e^{-\lambda(r + t)}  \, d\lambda
\end{align*}

After working through the previous section, you are hopefully ready to give this integral a go! The answer is given below.

::: callout-tryit
Show that $\frac {t^n}{n!} r \int_0^\infty \lambda^n e^{-\lambda(r + t)}  \, d\lambda = \frac{r t^n}{(r + t)^{n + 1}}$.
:::

This says that the marginal probability of a conditional Poisson with exponential intensity distribution is 
$$
P(N(t) = n) = \frac{r}{r + t}\left(\frac{t}{r + t}\right)^n
$$

In other words, $P(N(t) = n)$ is a *geometric* random variable with probability of success $\frac{r}{r + t}$.

## Theorems on Conditional Poisson Processes

::: {#thm-meanvarianceconditionalprocess}

## Mean and Variance of Conditional Poisson Process

The mean and variance of a conditional compound process with random intensity function $\Lambda$ are given as

$E[N(t)] = t E[\Lambda]$

${\mathrm{Var}}(N(t)) = t E[\Lambda] + t^2 {\mathrm{Var}}(\Lambda)$
:::

::: callout-tryit
Confirm the formulas for mean and variance of a conditional Poisson process in the special case that $\Lambda$ is an exponential random variable. (Hint: use the result in  @sec-poissongeometric!)
:::


## Simulations

In order to simulate from a conditional Poisson process, we first simulate a random sample $\lambda$ from $\Lambda$, and then we simulate a Poisson rv with rate $\lambda$.

Here we show how to simulate $N(3)$ when $\Lambda \sim$Unif(0, 1).

```{r}
sim_data <- replicate(10000, {
  lambda <- runif(1, 0, 1)
  rpois(1, 3 * lambda)
})
proportions(table(sim_data))
```

We see that the most likely outcome when $t = 3$ is that $N(3) = 0$. 


:::callout-tryit
Simulate $N(2)$ from a conditional Poisson process with random intensity $\Lambda \sim$Exp(1/3), and confirm that it appears to be a geometric distribution.
:::

```{r}
#| echo: false
#| eval: false

sim_data <- replicate(10000, {
  lambda <- rexp(1, 1/3)
  rpois(1, 2 * lambda)
})
proportions(table(sim_data))
dgeom(0:30, 1/3/(2 + 1/3))
```


:::callout-tryit
Complete Exercise 6.3 (a) in the textbook.
:::

## Conditional Distribution of $\Lambda$

If $N(t)$ is a conditional Poisson process and the random intensity rate $\Lambda$ has density $f(\lambda)$, then the conditional cumulative distribution function of $\Lambda$ given $N(t) = n$ is 

$$
F(\lambda|N(t) = n) = P(\Lambda \le \lambda|N(t) = n) = \frac{\int_0^\lambda u^n e^{-ut} f(u)\, du}{\int_0^\infty u^n e^{-ut} f(u)\, du}
$$

::: callout-tryit
If you are mathematically inclined, show that the conditional density function of $\Lambda$ given $N(t) = n$ (which is the derivative of the above function with respect to $\lambda$) is
$$
\frac{\lambda^n e^{-\lambda t} f(\lambda)}{\int_0^\infty u^n e^{-ut} f(u)\, du}
$$
:::

::: callout-tryit
Let $N(t)$ be a conditional Poisson process with random intensity $\Lambda$ which is exponentially distributed with rate $r = 1$.

- Find $P(\Lambda \le 1)$.
- Do you think $P(\Lambda \le 1|N(3) = 1)$ is less than, greater than, or equal to your answer above?
- Find $P(\Lambda \le 1|N(3) = 1)$.
:::
