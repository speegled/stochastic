[
  {
    "objectID": "compound_poisson.html",
    "href": "compound_poisson.html",
    "title": "1  Compound Poisson Processes",
    "section": "",
    "text": "In this chapter, we consider a stochastic process \\(X(t)\\) which is not necessarily a counting process. We say \\(X(t)\\) is a compound Poisson process if [ X(t) = _{i = 1}^{N(t)} Y_i ] where \\(N(t)\\) is a Poisson process with rate \\(\\lambda\\) and \\(Y_1, \\ldots\\) are independent, identically distributed random variables, which are also independent of \\(N(t)\\).\nOther examples given in the text include the number of people involved in car accidents at a certain intersection, the amount of money that visitors to a casino lose, and number of people entering a movie theater.\nWe can compute the mean and variance of a compound Poisson process as follows:\nLet’s look at a simulation of a compound Poisson process in order to check these results via an example. We assume that \\(N(t)\\) is a Poisson process with rate 2, and \\(Y_i\\) are iid uniform random variables on the interval \\([0, 1]\\). From Theorem Theorem 1.1, we see that [ E[X(3)] = 2 = 3 ] and [ {}(X(t)) = 3 _0^1 x^2, dx = 2 ] We check this via a simulation. Note that we don’t need to know when the events occur exactly, only how many of them there are before time \\(t = 3\\). That is given by rpois(1, 6)`, as below.\nThat is how we simulate a single trial of the compound Poisson process. To do multiple trials, we put it inside of replicate.\nIf you run the above code a few times, you will see that the mean and variance of the compound Poisson process are as predicted by Theorem Theorem 1.1."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Stochastic Processes with R",
    "section": "",
    "text": "These are notes to accompany STAT 4930/STAT 5930 at Saint Louis University."
  },
  {
    "objectID": "compound_poisson.html#modeling-a-compound-poisson-process",
    "href": "compound_poisson.html#modeling-a-compound-poisson-process",
    "title": "1  Compound Poisson Processes",
    "section": "\n1.1 Modeling a Compound Poisson Process",
    "text": "1.1 Modeling a Compound Poisson Process\nIn this section, we are interested in the reverse problem: if we are given data, how do we estimate \\(\\lambda\\) and the distribution of \\(Y_1, \\ldots, Y_{N(t)}\\)? For our purposes, we will make some assumptions about what kind of random variable \\(Y_1, \\ldots, Y_n\\) are and then use a goodness-of-fit test to see whether it is a reasonable fit to the data.\nWe start by modeling data that we know the true generative process of. This is so that we can see that out technique is working. In the next example, we will apply our technique to data that we don’t know the true generative process for.\n\n1.1.1 Simulated data\nWe assume that \\(N(t)\\) is Poisson with rate 2, and that \\(Y_1, \\ldots, Y_{N(t)}\\) are iid zero-truncated Poisson random variables with rate 3. Let’s imagine that this is the number of people entering a movie theater. For our simulated data, we are going to assume that we have collected data from time 0 to time 4, and we noted the time of arrival and the number of We create our simulated data as follows. The arrival times \\(S_1, \\ldots, S_{N(t)}\\) say when the groups arrived to the theater, and the values \\(Y_1, \\ldots, Y_{N(t)}\\) say how many people were in each group. We use zero-truncated Poisson because we are assuming that each \\(Y_i > 0\\).\n\nlambda <- 2\nt <- 4\nnum_events <- rpois(1, lambda * t)\ntime_of_events <- sort(runif(num_events, 0, t))\nnum_in_family <- actuar::rztpois(num_events, 3) #sampling from zero-truncated\ndata.frame(trial = 1,\n           time = time_of_events,\n           num_in_family = num_in_family)\n\n  trial      time num_in_family\n1     1 0.1359948             4\n2     1 0.8135919             3\n3     1 1.4918891             1\n4     1 2.8438165             2\n5     1 3.1943059             7\n\n\nTo create a large sample of this type, we use purrr::map_df.\n\nset.seed(1)\nsim_data <- purrr::map_df(1:300, function(x) {\n  num_events <- rpois(1, lambda * t)\n  time_of_events <- sort(runif(num_events, 0, t))\n  num_in_family <- actuar::rztpois(num_events, 3) #sampling from zero-truncated\n  data.frame(trial = x,\n             time = time_of_events,\n             num_in_family = num_in_family)\n})\n\nFirst things first, let’s check whether every trial had at least one family arrive:\n\nlength(unique(sim_data$trial)) #yep!\n\n[1] 300\n\n\nIn order to estimate the rate of the Poisson process \\(N(t)\\), we recall that the expected value of \\(N(4)\\) is \\(4\\lambda\\). We can estimate \\(E[N(4)]\\) from the data by counting the total number of occurrences by time 4, and dividing by the total number of trials. In other words,\n\nnrow(sim_data)/300\n\n[1] 7.88\n\n\nOur estimate for trhe mean of \\(N(4)\\) is 7.88, so our estimate for \\(\\lambda\\) is our previous estimate divided by 4; namely, 1.97. You should compare that to the true value of 2.\nNow we turn to estimating the mean of the truncated Poisson process. The method of moments estimator for \\(\\lambda\\), is given by [ = ] where \\(\\overline{x}\\) is the sample mean. We compute the sample mean as follows:\n\nmean(sim_data$num_in_family)\n\n[1] 3.136633\n\n\nand to solve for \\(\\hat \\lambda\\), well, that is a bit tricky, but we already know it is 3. Let’s just check:\n\n3/(1 - exp(-3))\n\n[1] 3.157187\n\n\nPretty good. If we want to solve for \\(\\hat \\lambda\\), we can use optimize:\n\noptimize(f = function(lambda) {(lambda/(1 - exp(-lambda)) - mean(sim_data$num_in_family))^2 },\n         interval = c(0, 10))\n\n$minimum\n[1] 2.976806\n\n$objective\n[1] 2.212965e-12\n\n\nOur estimate \\(\\hat \\lambda\\) is given by the value in $minimum. We can also check via a plot that it is about \\(\\hat \\lambda = 3\\).\n\ncurve(x/(1 - exp(-x)), from = 0, to = 5)\nabline(h = mean(sim_data$num_in_family))\nabline(v = 3, lty = 2, col = 2)\n\n\n\n\n\n1.1.2 Non-simulated data\nWe consider the airplane crash data from Kaggle. I imagine that airplane crashes are not a homogeneous Poisson process over the time frame of this data set (1908-present), because, well, that would just be too much to believe! Safety has improved (surely) but also the number of flights has increased, so it is not at all clear what to make of it. We’ll probably need to restrict down to a time interval where the rate of crashes is approximately constant.\n\nlibrary(tidyverse)\ndd <- read.csv(\"data/airplane_crashes.csv\") %>% \n  janitor::clean_names()\ndd <- as_tibble(dd)\ndd\n\n# A tibble: 5,268 × 14\n   index date      time  locat…¹ opera…² flight route type  regis…³ cn_in aboard\n   <int> <chr>     <chr> <chr>   <chr>   <chr>  <chr> <chr> <chr>   <chr>  <dbl>\n 1     0 09/17/19… \"17:… Fort M… Milita… \"\"     \"Dem… Wrig… \"\"      \"1\"        2\n 2     1 07/12/19… \"06:… Atlant… Milita… \"\"     \"Tes… Diri… \"\"      \"\"         5\n 3     2 08/06/19… \"\"    Victor… Private \"-\"    \"\"    Curt… \"\"      \"\"         1\n 4     3 09/09/19… \"18:… Over t… Milita… \"\"     \"\"    Zepp… \"\"      \"\"        20\n 5     4 10/17/19… \"10:… Near J… Milita… \"\"     \"\"    Zepp… \"\"      \"\"        30\n 6     5 03/05/19… \"01:… Tienen… Milita… \"\"     \"\"    Zepp… \"\"      \"\"        41\n 7     6 09/03/19… \"15:… Off Cu… Milita… \"\"     \"\"    Zepp… \"\"      \"\"        19\n 8     7 07/28/19… \"\"    Near J… Milita… \"\"     \"\"    Schu… \"\"      \"\"        20\n 9     8 09/24/19… \"01:… Biller… Milita… \"\"     \"\"    Zepp… \"\"      \"\"        22\n10     9 10/01/19… \"23:… Potter… Milita… \"\"     \"\"    Zepp… \"\"      \"\"        19\n# … with 5,258 more rows, 3 more variables: fatalities <dbl>, ground <dbl>,\n#   summary <chr>, and abbreviated variable names ¹​location, ²​operator,\n#   ³​registration\n# ℹ Use `print(n = ...)` to see more rows, and `colnames()` to see all variable names\n\n\nThe first thing I want to do is create a single date/time variable that encodes the time of the crash. To do so, we use the R package lubridate. If a crash doesn’t have an associated time, we just assume it happened at noon. I don’t think that will make a difference, but we will need to make sure our bins are not too small, in which case it would make a difference. Alternatively, I could’ve deleted those, but that seems like a lot of data to delete (42 percent!). One stil fails to parse (index 3267) because there is a typo in the time (114:20). Let’s assume they meant 14:20.\n\nmean(dd$time == \"\")\n\n[1] 0.4212225\n\ndd <- dd %>% \n  mutate(time = ifelse(time == \"\", \"12:00\", time)) %>% \n  mutate(time = ifelse(time == \"114:20\", \"14:20\", time)) %>% \n  mutate(date_time = lubridate::mdy_hm(paste0(date, time, sep = \" \")))\n\nWe also want to restrict to fatal airplane crashes for the purposes of this exercise, as this data set is probably missing quite a few crashes that were not fatal.\n\ndd <- dd %>% \n  filter(fatalities > 0)\n\nOK, now let’s get a histogram of the number of accidents over time.\n\nggplot(dd, aes(x = date_time)) + \n  geom_histogram(bins = 100)\n\n\n\n\nWe can see that this is almost surely not a homogeneous Poisson process, but if we restrict to, say, 1990-2000 it might be. Let’s check it out.\n\naa <- dd %>% \n  filter(date_time > lubridate::mdy(\"12/31/1989\") & date_time < lubridate::mdy(\"1/1/2001\"))\nhist(aa$date_time, breaks = 36)\n\n\n\n\nLet’s check to see whether this passes a goodness-of-fit test for a homogeneous Poisson process. We estimate the rate in terms of accidents per year. Note that there are 11 years in the data. We need to be really careful with units here! The units in breaks are seconds and we computed the rate in terms of years! We also need to check the number of bins that hist makes; just because you tell it to do 30, for example, doesn’t mean that there will be exactly 30 bins!!\n\n\n\n\n\n\nTryit\n\n\n\nCreate a histogram using hist(aa$date_time, breaks = 30), and count the number of bins. (It is the length of the counts variable that hist creates.) You’ll see it is not 30!\n\n\n\nrate <- 835/11\nss <- hist(aa$date_time, breaks = 36, freq = T)\n\n\n\n\nWe now compute the expected and the observed number of accidents in each bin based on our estimate of the rate being round(rate, 2). The variable ss$counts contains the observed values in the bins, so we just need to compute the expected value.\n\nobserved_accidents <- ss$counts\nexpected_accidents <- rate * (640000000 - 630000000)/31557600\ntest_stat <- sum((observed_accidents - expected_accidents)^2/expected_accidents)\npchisq(test_stat, df = 35 - 1 - 1, lower.tail = F)\n\n[1] 0.1146546\n\n\nWe fail to reject that airplane crashes are a homogeneous Poisson process. Let’s continue now with fatalities. That is surely not a homogeneous Poisson process, because it violates the assumption that multiple occurrences cannot happen at the same time. Let’s see what the distribution of fatalities looks like.\n\nhist(aa$fatalities)\n\n\n\n\nIt is really right skew. Maybe Poisson? No, for Poisson the mean is equal to the variance and check out our data!\n\nmuhat <- mean(aa$fatalities, na.rm = T)\nvarhat <- var(aa$fatalities, na.rm = T)\nmuhat\n\n[1] 21.93054\n\nvarhat\n\n[1] 1472.187\n\n\nMany times when modeling a discrete rv with variance larger than the mean, we use negative binomial random variables. We choose the size and mu parameter to match the mean and variance of our data. The variance is mu + mu^2/size in this parametrization. Solving for size we get\n\\[\n\\mu^2/(\\widehat{\\mathrm{Var}(x)} - \\mu) = \\mathrm{size}\n\\]\nThis is our estimate for the size parameter.\n\nsizehat <- muhat^2/(varhat - muhat)\nsizehat\n\n[1] 0.33163\n\n\nThe histogram of a random sample from a negative binomial random variable with this size and mean looks pretty close to what we have.\n\nhist(rnbinom(851, size = sizehat, mu = muhat))\n\n\n\n\nThis seems to be a reasonable model so far. \\(X(t)\\) is a compound Poisson process with rate \\(\\lambda = 77.36\\) per year, and \\(Y_1, \\ldots, Y_{N(t)}\\) iid negative binomial random variables with size 0.33 and mean 21.9. We have already checked whether the occurrences are approximately a Poisson process, let’s see how to check whether the total fatalities are approximately negative binomial with parameters estimated above.\nWe first set up our bins for the number of fatalities. We’ll set them up so that we have about the same number of expected outcomes in each bin.\n\nqnbinom(seq(0, 1, length.out = 20), size = sizehat, mu = muhat)\n\n [1]   0   0   0   0   0   1   1   2   3   5   7  10  14  18  24  32  44  62  95\n[20] Inf\n\n\nRuh-Roh!!! We forgot that we restricted to crashes that had a positive number of fatalities! The most likely outcome for a negative binomial random variable is 0! I don’t need to check whehter this is correct, it is obviously incorrect. Let’s just look at the observed and expected for small values of fatalities.\n\ntable(aa$fatalities)[1:10]\n\n\n 1  2  3  4  5  6  7  8  9 10 \n76 73 75 49 55 37 31 39 27 33 \n\nround(dnbinom(0:11, size = sizehat, mu = muhat) * 851)\n\n [1] 211  69  45  35  28  24  21  19  17  16  14  13\n\n\nWhat we needed was a zero-truncated negative binomial random variable. This is similar to the zero-truncated Poisson above, and we just need to know how to estimate the parameters associated with it. We see it has two parameters, size and prob, and the mean and variance are given in the help page. We need to find a combination of size and prob that leads to the observed mean and variance.\n\nmu <- function(r, p) {\n  r*(1-p)/(p*(1-p^r)) \n}\nvari <- function(r, p) {\n  (r*(1-p)*(1-(1+r*(1-p))*p^r))/(p*(1-p^r))^2 \n}\n\noptim(par = list(r = .08, p= .012), fn = function(x) {\n  r <- x[1]\n  p <- x[2]\n  (mu(r,p) - muhat)^2 + (vari(r,p) - varhat)^2\n})\n\n$par\n         r          p \n0.08016187 0.01211808 \n\n$value\n[1] 9.701981e-06\n\n$counts\nfunction gradient \n     101       NA \n\n$convergence\n[1] 0\n\n$message\nNULL\n\nr <- .08016\np <- .012118\nhist(actuar::rztnbinom(850, size = r, prob = p))\n\n\n\n\nNow, we check whether the observed counts are close enough to the expected counts. The expected count falls below 5 when the number of fatalities is 30, so we bin together 30+.\n\n\n\n\n\n\nTryit\n\n\n\nYou could also make more bins by binning together 30-40, 41-50, 51-60, 61-70, 71-80, 81-90, and 91+. This makes the R code a bit more challenging, but you should try to do it!\n\n\n\nprobs <- c(actuar::dztnbinom(1:30, r, p), 1 - sum(actuar::dztnbinom(1:30, r, p)))\nexpected <- 835 * probs\nobserved <- table(aa$fatalities)\nobserved <- c(observed[1:30], sum(observed[31:117]))\nteststat <- sum((expected - observed)^2/expected)\npchisq(teststat, df = 31 - 1 - 3, lower.tail = F)\n\n[1] 6.03795e-12\n\n\nWe reject the null hypothesis that a zero-truncated negative binomial random variable is a good model for this data. Darn it!"
  }
]